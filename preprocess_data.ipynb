{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from utils import extract_patch\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Extract Coin Patches from the annotated images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to extract the data from the file. The annotated images are COCO format. The data is in the form of a dictionary with the following keys:\n",
    "- `info`: Information about the dataset\n",
    "- `licenses`: License information\n",
    "- `images`: Image information\n",
    "- `annotations`: Annotation information\n",
    "- `categories`: Category information\n",
    "\n",
    "We are interested in the `images` and `annotations` keys. The `images` key contains information about the images, such as the image ID, file name, and image size. The `annotations` key contains information about the annotations, such as the annotation ID, image ID, category ID, and bounding box coordinates.\n",
    "\n",
    "For each annotation, we will extract the coin patch from the image using the bounding box coordinates.\n",
    "\n",
    "The coin patches are then saved as separate images in a new directory. With the images, we create a `labels.csv` file that contains the file name, category ID, and bounding box coordinates for each coin patch.\n",
    "\n",
    "The image size is 1400x1400 pixels, and the coin patch is centered in the image.\n",
    "\n",
    "We have seen that the largest coin fits into an 860x860 pixel square. To allow for rotation augmentation, we used 1400x1400 pixel square to extract the coin patch.\n",
    "\n",
    "The final augmented coin patch sizes saved are 900x900 pixels to allow for some margin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330/330 [00:24<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:02<00:00, 18.55it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def patches_from_coco(source,dest):\n",
    "    if not os.path.exists(os.path.join(dest, \"patches\")):\n",
    "        os.makedirs(os.path.join(dest, \"patches\"))\n",
    "    else:\n",
    "        shutil.rmtree(os.path.join(dest, \"patches\"))\n",
    "        os.makedirs(os.path.join(dest, \"patches\"))\n",
    "\n",
    "    # Load the data from the file\n",
    "    data = json.load(open(os.path.join(source, \"annotations.json\")))\n",
    "\n",
    "    id_to_label = { e[\"id\"]:e[\"name\"] for e in data[\"categories\"]}\n",
    "    id_to_label\n",
    "\n",
    "    id_to_images = { e[\"id\"]:e[\"file_name\"] for e in data[\"images\"]}\n",
    "\n",
    "    annotations = data[\"annotations\"]\n",
    "\n",
    "\n",
    "    df_labels = pd.DataFrame(columns=[\"name\",\"label\", \"image\", \"bbox\"])\n",
    "    for i,annotation in tqdm(list(enumerate(annotations))):\n",
    "        image_id = annotation[\"image_id\"]\n",
    "        label_id = annotation[\"category_id\"]\n",
    "        bbox = annotation[\"bbox\"] # \"bbox\": [x,y,width,height]\n",
    "        label = id_to_label[label_id]\n",
    "        image = id_to_images[image_id]\n",
    "        image_name = image.split(\".\")[0].replace(\"_\", \".\")\n",
    "        filepath = os.path.join(source, image)\n",
    "        patch = extract_patch(filepath, bbox, size=1400)\n",
    "        idx = str(i).zfill(3)\n",
    "        cv2.imwrite(os.path.join(dest, \"patches\", f\"{idx}.jpg\"), patch)\n",
    "        df_labels.loc[i] = [idx,label, image, bbox]\n",
    "    df_labels.to_csv(os.path.join(dest, \"patches\", \"labels.csv\"), index=False)\n",
    "\n",
    "print(\"Processing train\")\n",
    "patches_from_coco(\"data/train\",\"processed_data/train\")\n",
    "print(\"Processing val\")\n",
    "patches_from_coco(\"data/val\",\"processed_data/val\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 : Put the patches in the ImageFolder format for PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now save the images in the ImageFolder format, so that we can directly use the ImageFolder dataset from PyTorch to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 69.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 504.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def patches_to_ImageFolder(src, dest):\n",
    "    df = pd.read_csv(os.path.join(src,\"labels.csv\"))\n",
    "    # empty the dest folder\n",
    "    if os.path.exists(dest):\n",
    "        shutil.rmtree(dest)\n",
    "    # create the folder\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "    df[\"label\"].unique()\n",
    "\n",
    "    for label in tqdm(df[\"label\"].unique()):\n",
    "        os.makedirs(dest + label, exist_ok=True)\n",
    "        for i, row in df[df[\"label\"]==label].iterrows():\n",
    "            idx = str(row[\"name\"]).zfill(3)\n",
    "            shutil.copy(src + idx + \".jpg\", dest + label + \"/\" + idx + \".jpg\")\n",
    "print(\"Processing train\")\n",
    "patches_to_ImageFolder(\"processed_data/train/patches/\", \"processed_data/train/folder_dataset/\")\n",
    "print(\"Processing val\")\n",
    "patches_to_ImageFolder(\"processed_data/val/patches/\", \"processed_data/val/folder_dataset/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Perform data augmentation on the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that the data is not balanced in the dataset. We decided to perform data augmentation both for the balancing of the dataset and to increase its size.\n",
    "\n",
    "We use the following transformations:\n",
    "- Random translation, to simulate the coin being off-center\n",
    "- Random rotation, to train the model on different orientations of the coin\n",
    "- Random brightness, to simulate different lighting conditions\n",
    "- Random contrast, to simulate different lighting conditions\n",
    "- Random blur, to simulate different focus conditions\n",
    "\n",
    "the code for the data augmentation is in the `utils.py` file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import random_rotation, random_translation, random_brightness, random_contrast, random_blur, extend_patch, crop_around_center\n",
    "\n",
    "def augment_patch(patch, angle_range, translation_range, brightness_range, contrast_range, blur_range):\n",
    "    original_shape = patch.shape[:2]\n",
    "    to_add = 2\n",
    "    patch = extend_patch(patch, (original_shape[0]+to_add, original_shape[1]+to_add))\n",
    "    patch = random_rotation(patch, angle_range)\n",
    "    patch = random_translation(patch, translation_range)\n",
    "    patch = random_brightness(patch, brightness_range)\n",
    "    patch = random_contrast(patch, contrast_range)\n",
    "    patch = random_blur(patch, blur_range)\n",
    "    patch = patch[to_add//2:-to_add//2, to_add//2:-to_add//2]\n",
    "    patch = crop_around_center(patch, 900)\n",
    "    return patch\n",
    "def perform_augmentation(source_folder,target_folder, target_number_per_class,augmentation_params):\n",
    "    \"\"\"\n",
    "        source_folder: str, path to the folder containing the patches; each class should be in a separate folder\n",
    "        target_folder: str, path to the folder where the augmented patches will be saved; each class will be in a separate folder\n",
    "        target_number_per_class: int, total number of patches per class after augmentation\n",
    "    \"\"\"\n",
    "    classes = os.listdir(source_folder)\n",
    "\n",
    "    angle_range = augmentation_params[\"angle_range\"]\n",
    "    translation_range = augmentation_params[\"translation_range\"]\n",
    "    brightness_range = augmentation_params[\"brightness_range\"]\n",
    "    contrast_range = augmentation_params[\"contrast_range\"]\n",
    "    blur_range = augmentation_params[\"blur_range\"]\n",
    "    for class_name in tqdm(classes):\n",
    "        os.makedirs(target_folder + class_name, exist_ok=True)\n",
    "        patches = os.listdir(source_folder + class_name)\n",
    "        patches = [p for p in patches if p.endswith(\".jpg\")]\n",
    "        n = len(patches)\n",
    "        for i in range(target_number_per_class):\n",
    "            if i < n:\n",
    "                patch_path = patches[i]\n",
    "                patch = cv2.imread(source_folder + class_name + \"/\" + patch_path)\n",
    "                patch = crop_around_center(patch, 900)\n",
    "                idx = str(i).zfill(3)\n",
    "                cv2.imwrite(target_folder + class_name + \"/\" + idx + \".jpg\", patch)\n",
    "            else:\n",
    "                patch_path = np.random.choice(patches)\n",
    "                patch = cv2.imread(source_folder + class_name + \"/\" + patch_path)\n",
    "                patch = augment_patch(patch, angle_range, translation_range, brightness_range, contrast_range,blur_range)\n",
    "                idx = str(i).zfill(3)\n",
    "                cv2.imwrite(target_folder + class_name + \"/\" + idx + \".jpg\", patch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [06:06<00:00, 15.92s/it]\n"
     ]
    }
   ],
   "source": [
    "augmentation_params = {\n",
    "    \"angle_range\":(0,360),\n",
    "    \"translation_range\":(-20,20),\n",
    "    \"brightness_range\":(-20,20),\n",
    "    \"contrast_range\":(0.8,1.2),\n",
    "    \"blur_range\":(0,10)\n",
    "}\n",
    "\n",
    "perform_augmentation(\"processed_data/train/folder_dataset/\", \"processed_data/train/augmented_dataset/\", target_number_per_class=300, augmentation_params=augmentation_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
